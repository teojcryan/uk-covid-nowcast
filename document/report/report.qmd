---
title: "Nowcasting COVID-19 incidence in England"
author: 
  - name: "Ryan Teo"
    affiliation: Mathematics of Real-World Systems CDT, Mathematics Institute, University of Warwick
    #affiliation-url: https://example.com/
format:
  html: 
    toc: true
    #lof: true
    #lot: true
    number-sections: true
    number-depth: 3
    keep-tex: true
    colorlinks: true
    papersize: A4
    documentclass: article
    #cite-method: biblatex
    link-citations: true
    geometry:
      - margin=1in
bibliography: references.bib
csl: ieee.csl
---

# Introduction

<!--- Present the nature and scope of problem investigated --->

During infectious disease outbreaks, epidemiological indicators such as the incidence of cases and hospitalisations are often used to assess changes in epidemic dynamics in real-time. However, these indicators often suffer from reporting delays, resulting in them appearing artificially low towards the present day. This results in newly reported indicators being a lagging indicator of past events. 

<!--- What else has been done for nowcasting --->

[@cox1989]

-   parametric approach to predicting point processes in the presence of notification delays
-   

[@lawless1994]

-   Nonparametric methods that are well-suited for when daily number of events are moderately large
-   Estimating reporting-delay probabilities from recent data
-   Incorporates unobservable random effects in reporting delays
-   Both allow for time-varying reporting-delay distributions

[@höhle2014]

-   

[@schneble2021]

One study [@seaman2022]

[@abbott2021]

[@günther2021]

<!-- Objective -->

In this study, we aim to evaluate the utility of semi-parametric nowcasting model formulations generated from publicly available data on COVID-19 cases by specimen date in England. Additionally, we aim to assess the impact of reporting structures (including weekends, bank holidays, and reporting schedules) on the accuracy of nowcasts. 

This work has vital applications to the real world. Developing an understanding of the impact of changing reporting schedules, such as the recent decision by the UK Health Security Agency (UKHSA) to change from week-daily to weekly reporting on 1st July 2022, may be useful to data providers.

# Methods

## Data

-   New COVID-19 cases by specimen date
-   UK COVID-19 dashboard, containing archived data
-   Feb 2021 to present
-   Reported weekdaily until Jul 2022, then weekly
-   New cases data stratified by age and region, but right-truncated by 5 days and is unsuitable for estimating reporting delays

## Models
We adapt the notation used in previous approaches [@lawless1994] to describe the nowcasting of discrete count data. Let $n_{t,d}$ be the number of cases which are tested on day $t\in \{0,...,T\}$ and are reported with a delay of $d\in\{0,...,D\}$ days. $D$, which represents the maximum delay that can occur, can theoretically be infinite, but here we set it to be finite for the model to be computationally feasible and identifiable. Furthermore, longer delays provide information too far in the past to be relevant. Specifically, we set $D=7$ days after estimating that x of cases by a specimen date were eventually reported by the 7th day after. The final observed count for day $t$ is thus $$N_t = \sum_{d=0}^D n_{t,d}$$

We assume that for each reference date $t$, the number of cases reported with a delay of $d$ follow a multinomial distribution with $N_t$ trials and a probability vector $p_{t,d}$ of length $D$. The objective of nowcasting is to use information available up to time $t$ to estimate the components of $p_{t,d}$ jointly with the expected number of final notifications $(\lambda_t = \mathbb{E}[N_t])$ and predict the final observed counts $N_t$.

### Expected final notifications

The expected final notifications are modelled as a first order random walk over time [@günther2021], specified as such

$$
\begin{aligned}
\log(\lambda_0) &\sim N\left(\log(N_0+1),1\right), \\
\log(\lambda_t)|\lambda_{t-1} &\sim N(\log(\lambda_{t-1}), \sigma^2)\\
\sigma^2 &\sim \text{Half-Normal}(0,1)
\end{aligned}
$$

### Delay distribution

The delay distribution $p_{t,d}$ is estimated using a discrete-time logistic hazard model $$h_{t,d}=\mathbb{P}(\text{delay}=d|\text{delay} \geq d, W_{t,d})$$ where $W_{t,d}$ is decomposed into 2 components:

1.  Hazard derived from a parametric delay distribution $\gamma_{t,d}$ dependent on covariates at time of reference
2.  Hazard dependent on covariates referenced to the time of report $\epsilon_{t,d}$

#### Parametric hazard at reference time

The first component $\gamma_{t,d}$ can be thought of as the probability of reporting $p'_{t,d}$ at a given time $t$ if it followed a parametric distribution. Here, the probability follows a discretised log normal distribution as such

$$
\begin{aligned}
p'_{t,d} &\sim \text{LogNormal}(\gamma_t,v_t)\\
\gamma_t &= \mu_0 + \alpha_\mu X_\gamma+\beta_\mu Z_\gamma\\
v_t &= \exp\left(v_0 + \alpha_v X_\gamma + \beta_v Z_\gamma\right)
\end{aligned}
$$

The distribution is normalised so it sums to 1. The resulting parametric logit hazard, which is the probability of report at a given time given that it has not already been reported for this component of the model is $$\gamma_{t,d} = \text{logit}\left(\frac{p'_{t,d}}{\left(1-\sum_{d'=0}^{d-1}p'_{t,d'}\right)}\right)$$

#### Non-parametric hazard at report times

Non-parametric effects by report dates are represented by non-distributional logit hazard components for the respective times defined using an intercept and arbitrary shared covariates with fixed $\alpha_\epsilon$ and random $\beta_\epsilon$ coefficients

$$
\begin{aligned}
\epsilon_{t,d} &= \alpha_\epsilon X_\epsilon + \beta_\epsilon Z_\epsilon
\end{aligned}
$$

The overall hazard for each reference time and delay is then $$\text{logit}(h_{t,d}) = \gamma_{t,d}+\epsilon_{t,d}$$ where the hazard on the final day has been assumed to be 1, i.e. $h_{t,D}=1$ to enforce the constraint that all reported observations are reported within the specified maximum delay. The probability of a report for a given delay, reference time is then as follows

$$
\begin{aligned}
p_{t,0} &= h_{t,0} \\
p_{t,d} &= \left(1 - \sum_{i=0}^{d-1} p_{t,i}\right) h_{t,d}
\end{aligned}
$$

All fixed $\alpha$ and random $\beta$ coefficients have standard normal priors by default, while pooled standard deviations have standard half-normal priors.

### Observation model and nowcast

The product of the expected final notifications for each reference time $t$ and the probability of reporting for each day of delay $p_{t,d}$ now returns the expected notifications by $t$ and reporting delay.

We assume a negative binomial observation model with a joint overdispersion parameter with a standard half normal prior on the inverse square root of the overdispersion. A nowcast of final observed notifications at each reference time $t$ can be obtained by taking the sum of posterior estimates for both unobserved and observed notifications for that reference time.

$$
\begin{aligned}
n_{t,d}\ |\  \gamma_{t,d}, p_{t,d} &\sim \text{NegBin}(\lambda_t\times p_{t,d}, \phi),\quad t=1,...,T\\
\frac{1}{\sqrt{\phi}} &\sim \text{Half-Normal}(0,1) \\
N_t &= \sum_{d=0}^D n_{t,d}
\end{aligned}
$$


### Model formulations

| Model | Reporting Delays       | Reporting Schedule |
|-------|------------------------|--------------------|
| 1     | Fixed                  | Week Daily         |
| 2     | Weekend                | Week Daily         |
| 3     | Day of Week & Holidays | Week Daily         |
| 4     | Day of Week & Holidays | Weekly             |

-   Simulated 4 chains for 1,000 iterations and 1,000 for warm-up
-   Analysis was carried out using `R` version 4.1.0 [@rcoreteam2022]
-   Implemented using the `epinowcast` package version 0.1.0
-   Source code is available on GitHub

## Implementation


## Evaluation

-   Metric needs to be able to evaluate predictions provided in an interval or quantile format
-   Interval Score [@gneiting2007]

$$\text{IS}_\alpha(F,y) = (u-l)+\frac{2}{\alpha}\times (l-y)\times \mathbb{I}(y<l) + \frac{2}{\alpha}\times(y-u)\times\mathbb{I}(y>u)$$

-   Weighted Interval Score [@bracher2021] is composed of dispersion, overprediction, and underprediction.

$$\text{WIS}_{\alpha_{\{0:K\}}}(F,y)=\frac{1}{K+1/2}\times\left(w_0\times |y-m| + \sum_{k-1}^K\{w_k\times\text{IS}_{\alpha_k}(F,y)\}\right)$$

-   Proper scoring rule, weighted interval score
-   Implemented by `scoringutils` package version 1.0.0 [@bosse]

# Results

## Visualisation
- Plot of nowcasts by estimation date

## Evaluation
- Comparison of models by Weighted Interval Score and its components

## Diagnostics


# Discussion

-   Summarise project
-   Discuss strengths and limitations of evaluation
    + Limitations
        + Test types, dealing with removals
        + Specimen date $\neq$ onset date
        + Dependent on testing regime
-   Compare to literature
-   Discuss further work
-   Summarise conclusions

# Conclusion

-   Summarise findings
-   Restate relevance to current literature
-   Explain why this matters

# Appendix

## Exploratory analysis of dashboard data

-   Describe the change in mean reporting delay over time
-   Motivate the choice of time frame chosen in study?

![COVID-19 cases in England by proportion of delay](images/cases-delay-england.png)

(top) New cases by specimen date. Colors represent the delay during which cases were reported. (bottom) Proportion of new cases that are reported by varying delays. Black line represents mean delay.

## Long delays

-   This section illustrates how long reporting delays can be in real-world data 
-   convince reader that extra-long delays are caused by logistical issues rather than factors affecting transmission and can be ignored

![Distribution of long delays](images/long-delay-dist.png)

(left) The frequency of updates by specimen date and delay. The hue intensity reflects the number of updates made to the number of new cases on each specimen date with a delay indicated by the y-axis. The red diagonal line represents the maximum possible delay for each specimen date. (right) The number of updates made to past data on each reporting date. The red dotted lines represent two significant change points: the left marks when the linearly increasing number of updates ends, and the right highlights a particular reporting date on which there was an unusually large number of updates made to past data.

![Distribution of reporting delays](images/cases-delay-dist.png) (left) The mean proportion of cases reported with a delay $d$ for any specimen date, with 95% confidence intervals. (right) The mean proportion of cases reported by a delay $d$ for any specimen date, with 95% confidence intervals.

The distribution of reporting delays is right-skewed, which has a the greatest mean proportion at $d=2$. Cumulatively, 97.4% of cases are reported by day $d=7$. This suggests that it would be practical to take a maximum delay to be $d>7$.

## Test-specific case data

-   Explain that data on new cases is the sum of three separate data streams

![Distribution of reporting delays by test type](images/delay-dist-test-type.png)

The majority of cases reported initially are confirmed by LFDs whilst PCR results experience a longer lag. Due to false positives, the cases confirmed by LFDs also update in the negative direction. Lastly, the proportion of cases confirmed by LFD and PCR within 3 days forms the smallest proportion of total cases reported and is slightly less right skewed than PCR only cases. This is consistent with the understanding that the reporting lags for both a LFD and a PCR test are expected to be larger than just a PCR test.

<!-- Sample output of 7-day nowcast conducted in September 2021. Triangles represent eventually reported cases, while points represent the number of cases reported on the first day. Solid and dotted lines represent the mean and median nowcast, and the darker and lighter shaded regions represent the 90% and 30% confidence intervals. -->
